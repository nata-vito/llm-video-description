{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import ollama\n",
    "import whisper\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"dolphin-llama3:8b\")\n",
    "\n",
    "response = llm.invoke(\"O primeiro homem na lua foi...\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(audio_file = \"../audio/transcription.mp3\", verbose = True):\n",
    "    with open(\"../output/video_transcription.txt\", \"w\") as file:\n",
    "        logging.info('Starting speech to text processing...')\n",
    "        \n",
    "        model = whisper.load_model(\"medium\")\n",
    "        result = model.transcribe(audio_file)\n",
    "        \n",
    "        file.write(result[\"text\"])\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Text transcription\", result[\"text\"])\n",
    "            \n",
    "        return result[\"text\"]\n",
    "    \n",
    "    \n",
    "speech_to_text(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "    \"Fornecemos as informações de contexto abaixo. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"A partir desta informação, por favor responda a pergunta: {query_str}\\n\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_data = \"Baseando nos seus conhecimentos sobre desenvolvimento de soluções web, \\\n",
    "    por favor gere um planejamento para o layout de uma tela de aplicativo que compusesse todas as informações \\\n",
    "    mencionadas nessa conversa para um novo aplicatico contendo os pontos mencionados\"\n",
    "    \n",
    "prompt = qa_template.format(context_str=text_to_prompt, query_str=\"O que você melhoraria no texto para ser utilizado como prompt?\")\n",
    "\n",
    "response = ollama.chat(model=\"llama3.1\", messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "        },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "    \"Fornecemos as informações de contexto abaixo. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"A partir desta informação, por favor responda a pergunta: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "query_data_main = \"Você poderia organizar o texto?\"\n",
    "    \n",
    "query_data_main_goal = \"Baseando nos seus conhecimentos sobre desenvolvimento de soluções web, \\\n",
    "    por favor gere um planejamento para o layout de uma tela de aplicativo que compusesse todas as informações \\\n",
    "    mencionadas nessa conversa para um novo aplicatico contendo os pontos mencionados?\"\n",
    "\n",
    "test = \"\"    \n",
    "    \n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "# you can create text prompt (for completion API)\n",
    "with open(\"../output/transcription.txt\", \"r\") as transcription:\n",
    "    text_to_prompt = transcription.read()\n",
    "    \n",
    "    sumary_prompt = qa_template.format(context_str=text_to_prompt, query_str=query_data_main)\n",
    "    sumary_response = ollama.chat(model=\"dolphin-llama3:8b\", messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ])\n",
    "    \n",
    "    \"\"\" planning_prompt = qa_template.format(context_str=sumary_response['message']['content'], query_str=query_data_main_goal)\n",
    "    planning_response = ollama.chat(model=\"dolphin-llama3:8b\", messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ]) \"\"\"\n",
    "    \n",
    "    print(sumary_response['message']['content'])\n",
    "    \n",
    "    # print(planning_response['message']['content'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/transcription.txt\", \"r\") as transcription:\n",
    "    logging.info('Language correction...')\n",
    "    text_to_prompt = transcription.read()\n",
    "    \n",
    "    prompt = f\"\"\"Você está corrigindo textos como um professor. Corrija os erros de português no texto a seguir modificando o que for necessário, mas mantendo a mesma estrutura. Segue o texto a ser modificado: {text_to_prompt}\"\"\"\n",
    "                 \n",
    "    response = ollama.chat(model=\"llama3.1\", messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ])\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    with open(\"../output/meeting_transcription.txt\", \"w\") as video_discription:\n",
    "        video_discription.write(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To auto video description based on audio transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/video_transcription.txt\", \"r\") as transcription:\n",
    "    logging.info('Creating descriptions...')\n",
    "    text_to_prompt = transcription.read()\n",
    "    \n",
    "    prompt = f\"\"\"Você é um criador de conteúdo expert em criar descrições engajadoras para vídeos a partir de textos.\\\n",
    "                Crie três descrições adaptadas para plataformas de vídeo em português-BR sendo que a primeira descrição deve ser generalista,\\\n",
    "                a segunda direta e a terceira descritiva. \n",
    "                Texto para descrever: {text_to_prompt}\\\n",
    "                \n",
    "                RESPOSTA:   \n",
    "                Descrição 1 ...\n",
    "                \n",
    "                Descrição 2 ...\n",
    "                \n",
    "                Descrição 3 ...\n",
    "                \"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"dolphin-llama3:8b\", messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ])\n",
    "    \n",
    "    data_response = response['message']['content']\n",
    "    \n",
    "    \n",
    "    logging.info('Language correction...')\n",
    "    with open(\"../output/video_transcription.txt\", \"w\") as video_discription:\n",
    "        logging.info('Creating file...')\n",
    "        \n",
    "        video_discription.write(response['message']['content'])\n",
    "        \n",
    "        logging.info('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração de um resumo com os pontos importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_text = speech_to_text(audio_file = \"../audio/2024_08_21_12_36_53paulo.mp3\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/transcription.txt\", \"r\") as transcription:\n",
    "    logging.info('Creating an overview...')\n",
    "    text_to_prompt = transcription.read()\n",
    "    \n",
    "    prompt = f\"\"\"Você é um especialista em desenvolvimento de apps e sites e está em uma reunião. Gere um resumo sobre a transcrição da reunião a seguir elencando os prontos principais do seu ponto de vista. \n",
    "                                \n",
    "                Transcrição da reunião: {text_to_prompt}  \n",
    "                \n",
    "                Resposta: Aqui esta o resumo... \n",
    "                \"\"\"\n",
    "                \n",
    "    response = ollama.chat(model='llama3.1', messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ])\n",
    "    \n",
    "    \"\"\"  data_response = response['message']['content']\n",
    "    \n",
    "    prompt = f'Corrija os erros de português no texto a seguir: {data_response}'\n",
    "    response = ollama.chat(model='llama3.1', messages=[{\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "         },\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"../output/video_transcription.txt\", \"w\") as video_discription:\n",
    "        logging.info('Creating file...')\n",
    "        video_discription.write(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
